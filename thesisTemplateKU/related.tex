
A lot of work has been happening in the ear biometrics over the past decade. The approaches are varied with some working on Intensity-based features while others on 2-D ad 3-D curves etc. Chang et al.[2003] whole worked on the UND database and got an accuracy of 72.7p.c. using the PCA approach. A new concept called Force-Field was being brought by Hurley et al. which gave an accuracy of 99.2 p.c. on the XM2VTS dataset. Many other approaches like 3D Features, Gabor Filters, SIFT, Wavelet Transformation have been applied on different databases and results have been obtained. This project is mostly on the analysis of Biometric Humar Ear datasets on two methods - SIFT and SURF and a comparison is given on the rotation and scaling factors and how the number of features varies on such conditions keeping the real life scenarios in mind where Ear images are not obtained as compared to a dataset.

Similar methods have been applied on other Biometics like face, fingerprint and others etc. Both Shallow and Deep methods have different significances. Shallow methods start by extracting a representation of the image using hand-crafted local image descriptors like SIFT, SURF ,LBP,HoG [5,13,22,23,32: Parkhi paper]' then the local features are being aggregated into an overall ace descriptor by using a pooling mechanism for example Fisher Vector[15,20:Parkhi paper]. The work of deep learning was initiated with the help of a CNN Feature Extractor , a learnable function obtained by composing several linear and non-linear operators. The best example can be shown in DeepFace[29:Parkhi paper] which uses deep CNN trained to classify faces using a dataset of 4 million examples spanning 4000 unique identities. Upon extensive research, new ideas were being incorporated using multiple CNNs[25:Parkhi paper].
